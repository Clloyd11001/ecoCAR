{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Clloyd11001/ecoCAR/blob/main/Training_YOLOv7_Stop_Lights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "# How to Train YOLOv7 on a Custom Dataset\n",
        "\n",
        "This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows training on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together.\n",
        "\n",
        "\n",
        "### **Accompanying Blog Post**\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv7](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/), concurrently.\n",
        "\n",
        "### **Steps Covered in this Tutorial**\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOv7 dependencies\n",
        "* Load custom dataset from Roboflow in YOLOv7 format\n",
        "* Run YOLOv7 training\n",
        "* Evaluate YOLOv7 performance\n",
        "* Run YOLOv7 inference on test images\n",
        "* OPTIONAL: Deployment\n",
        "* OPTIONAL: Active Learning\n",
        "\n",
        "\n",
        "### Preparing a Custom Dataset\n",
        "\n",
        "In this tutorial, we will utilize an open source computer vision dataset from one of the 90,000+ available on [Roboflow Universe](https://universe.roboflow.com).\n",
        "\n",
        "If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.\n",
        "\n",
        "Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD-uPyQ_2jiN",
        "outputId": "2497adc6-5584-4128-9513-978b5bd3ab95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 1139, done.\u001b[K\n",
            "remote: Total 1139 (delta 0), reused 0 (delta 0), pack-reused 1139\u001b[K\n",
            "Receiving objects: 100% (1139/1139), 70.41 MiB | 16.92 MiB/s, done.\n",
            "Resolving deltas: 100% (488/488), done.\n",
            "/content/yolov7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (1.22.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (4.7.0.72)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (2.27.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (1.10.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 12)) (0.15.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 13)) (4.65.0)\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 17)) (2.12.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 21)) (1.4.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 35)) (5.9.4)\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.26.15)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.10.7)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.25.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.40.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.4.3)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.53.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2022.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (2.14.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 17)) (6.1.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "# Download YOLOv7 repository and install requirements\n",
        "!git clone https://github.com/WongKinYiu/yolov7\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtJ24mPlyF-S"
      },
      "source": [
        "# Download Correctly Formatted Custom Data\n",
        "\n",
        "Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ovKgrVN8ygdW",
        "outputId": "9987d5ac-00e1-41c2-b748-2ba877a6fa5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.0.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m397.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.10\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (8.4.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.26.15)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.27.1)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting cycler==0.10.0\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.22.4)\n",
            "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2022.12.7)\n",
            "Collecting requests-toolbelt\n",
            "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.7.0.72)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.4.4)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.65.0)\n",
            "Collecting pyparsing==2.4.7\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (4.39.3)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (5.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (23.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->roboflow) (2.0.12)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.15.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=ecada481a4fd906c64bb6556a9d491d4748e673f6c5a1c5cf9d0f12562a5422c\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.0.9\n",
            "    Uninstalling pyparsing-3.0.9:\n",
            "      Successfully uninstalled pyparsing-3.0.9\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.11.0\n",
            "    Uninstalling cycler-0.11.0:\n",
            "      Successfully uninstalled cycler-0.11.0\n",
            "Successfully installed cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-0.10.1 roboflow-1.0.3 wget-3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in traffic-lights-1 to yolov7pytorch: 100% [80483463 / 80483463] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to traffic-lights-1 in yolov7pytorch:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4106/4106 [00:01<00:00, 2701.68it/s]\n"
          ]
        }
      ],
      "source": [
        "# REPLACE with your custom code snippet generated above\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"***YOUR API KEY GOES HERE***\")\n",
        "project = rf.workspace(\"version-ou-je-vais-merge\").project(\"traffic-lights-qh0vp\")\n",
        "dataset = project.version(1).download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHfT9gEiBsBd"
      },
      "source": [
        "# Begin Custom Training\n",
        "\n",
        "We're ready to start custom training.\n",
        "\n",
        "NOTE: We will only modify one of the YOLOv7 training defaults in our example: `epochs`. We will adjust from 300 to 100 epochs in our example for speed. If you'd like to change other settings, see details in [our accompanying blog post](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUbmy674bhpD",
        "outputId": "cbc2f69c-1f0f-49bf-da3c-be9b059d2b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "--2023-04-05 18:31:25--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230405T183014Z&X-Amz-Expires=300&X-Amz-Signature=d4f18654aad6728a96ab732daa1643d987867852260af483bf48003b157cff70&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-04-05 18:31:25--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230405T183014Z&X-Amz-Expires=300&X-Amz-Signature=d4f18654aad6728a96ab732daa1643d987867852260af483bf48003b157cff70&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: â€˜yolov7_training.ptâ€™\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M   173MB/s    in 0.4s    \n",
            "\n",
            "2023-04-05 18:31:26 (173 MB/s) - â€˜yolov7_training.ptâ€™ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download COCO starting checkpoint\n",
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iqOPKjr22mL",
        "outputId": "0184a9f4-00c3-47a9-c83d-b7e126ebbb6e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolov7\n",
            "2023-04-05 18:31:31.655812: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-05 18:31:33.180830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Namespace(weights='yolov7_training.pt', cfg='', data='/content/yolov7/traffic-lights-1/data.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=50, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     44944  models.yolo.IDetect                     [3, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37207344 parameters, 37207344 gradients, 105.1 GFLOPS\n",
            "\n",
            "Transferred 557/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'traffic-lights-1/train/labels' images and labels... 1423 found, 0 missing, 0 empty, 0 corrupted: 100% 1423/1423 [00:00<00:00, 3432.60it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: traffic-lights-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'traffic-lights-1/valid/labels' images and labels... 50 found, 0 missing, 0 empty, 0 corrupted: 100% 50/50 [00:00<00:00, 1913.58it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: traffic-lights-1/valid/labels.cache\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.91, Best Possible Recall (BPR) = 0.9995\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      0/49     2.17G   0.06961   0.01229   0.02116    0.1031        42       640: 100% 89/89 [01:50<00:00,  1.24s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:10<00:00,  5.01s/it]\n",
            "                 all          50          62       0.418       0.313      0.0946      0.0297\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/49     13.4G   0.05535  0.008285   0.01939   0.08302        57       640: 100% 89/89 [01:19<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.25it/s]\n",
            "                 all          50          62       0.112        0.17      0.0967      0.0377\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/49     11.6G   0.05031  0.008631   0.01899   0.07793        49       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.69it/s]\n",
            "                 all          50          62       0.326       0.555       0.395       0.179\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/49     11.6G   0.04827   0.00712   0.01835   0.07373        44       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.14it/s]\n",
            "                 all          50          62       0.362       0.694       0.403       0.259\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/49     11.6G   0.04787  0.006177   0.01712   0.07117        44       640: 100% 89/89 [01:19<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.17it/s]\n",
            "                 all          50          62       0.377       0.649       0.456       0.184\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/49     11.6G    0.0482  0.005689   0.01505   0.06894        33       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.18it/s]\n",
            "                 all          50          62       0.475       0.885       0.703       0.399\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/49     11.6G   0.04733  0.005546   0.01208   0.06495        36       640: 100% 89/89 [01:17<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.20it/s]\n",
            "                 all          50          62        0.57       0.749       0.752       0.277\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/49     11.6G   0.04625  0.005373   0.01078    0.0624        45       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.18it/s]\n",
            "                 all          50          62        0.76       0.559       0.649       0.447\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/49     11.6G   0.04331  0.005282   0.01012   0.05871        44       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.18it/s]\n",
            "                 all          50          62        0.81       0.889       0.919       0.515\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/49     11.6G   0.04364  0.005501  0.009294   0.05843        41       640: 100% 89/89 [01:19<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.07it/s]\n",
            "                 all          50          62       0.818       0.839       0.903       0.606\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/49     11.6G   0.04075   0.00539  0.008473   0.05461        35       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.08it/s]\n",
            "                 all          50          62       0.928       0.896       0.942       0.597\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/49     11.6G   0.03956  0.005433  0.008493   0.05349        32       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.15it/s]\n",
            "                 all          50          62       0.923       0.891       0.943       0.523\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/49       13G   0.03869  0.005118  0.007742   0.05155        42       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.07it/s]\n",
            "                 all          50          62       0.942       0.877       0.947       0.596\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/49       13G   0.03816  0.004882  0.007158    0.0502        29       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.05it/s]\n",
            "                 all          50          62       0.922       0.914       0.953       0.632\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/49       13G   0.03827  0.004867  0.007412   0.05055        34       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.15it/s]\n",
            "                 all          50          62       0.993       0.918       0.984       0.618\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/49       13G   0.03661  0.004871  0.006958   0.04844        36       640: 100% 89/89 [01:19<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n",
            "                 all          50          62        0.91       0.771       0.864       0.595\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/49       13G   0.03618  0.004695  0.005982   0.04686        42       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n",
            "                 all          50          62       0.879       0.951       0.937       0.622\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/49       13G   0.03535  0.004516   0.00583   0.04569        54       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.17it/s]\n",
            "                 all          50          62         0.9       0.915        0.95       0.683\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/49       13G   0.03403  0.004383  0.005539   0.04395        47       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.19it/s]\n",
            "                 all          50          62       0.979       0.961       0.988        0.79\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/49       13G   0.03394  0.004397  0.005805   0.04414        49       640: 100% 89/89 [01:17<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.12it/s]\n",
            "                 all          50          62       0.914       0.973       0.976       0.768\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/49       13G   0.03348  0.004367  0.005205   0.04305        42       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.14it/s]\n",
            "                 all          50          62       0.979       0.958       0.993       0.742\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/49       13G   0.03344  0.004481  0.005197   0.04312        28       640: 100% 89/89 [01:19<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.18it/s]\n",
            "                 all          50          62       0.996       0.961       0.989       0.756\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/49       13G   0.03275  0.004453   0.00458   0.04178        40       640: 100% 89/89 [01:19<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.21it/s]\n",
            "                 all          50          62       0.949       0.969       0.982       0.764\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/49       13G   0.03225  0.004467  0.004889    0.0416        31       640: 100% 89/89 [01:19<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.19it/s]\n",
            "                 all          50          62        0.98       0.972       0.987       0.769\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/49       13G    0.0323  0.004398   0.00446   0.04116        37       640: 100% 89/89 [01:19<00:00,  1.12it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.12it/s]\n",
            "                 all          50          62       0.984       0.961       0.994       0.765\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/49       13G   0.03206  0.004139   0.00445   0.04064        45       640: 100% 89/89 [01:17<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.21it/s]\n",
            "                 all          50          62       0.993       0.965       0.993       0.774\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/49       13G   0.03177  0.004198  0.004546   0.04051        43       640: 100% 89/89 [01:19<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.17it/s]\n",
            "                 all          50          62       0.989        0.98       0.992       0.773\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/49       13G    0.0311   0.00419  0.004051   0.03934        56       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.12it/s]\n",
            "                 all          50          62       0.973       0.965       0.984       0.773\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/49       13G   0.03145  0.004208  0.003852   0.03951        33       640: 100% 89/89 [01:17<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.11it/s]\n",
            "                 all          50          62       0.974       0.979       0.991       0.773\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/49       13G   0.03112  0.004125  0.003995   0.03924        40       640: 100% 89/89 [01:17<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n",
            "                 all          50          62       0.986        0.97       0.991       0.809\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     30/49       13G   0.03041  0.004302   0.00357   0.03828        45       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.19it/s]\n",
            "                 all          50          62       0.982       0.965       0.994       0.787\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     31/49       13G   0.03004  0.004195  0.003547   0.03778        47       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.15it/s]\n",
            "                 all          50          62       0.991       0.963       0.987       0.781\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     32/49       13G   0.03006  0.004096  0.003668   0.03782        47       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.14it/s]\n",
            "                 all          50          62       0.987       0.979       0.991       0.792\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     33/49       13G   0.02995  0.004047  0.003648   0.03764        34       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n",
            "                 all          50          62       0.974       0.983       0.992       0.794\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     34/49       13G   0.02963  0.004044  0.003305   0.03698        31       640: 100% 89/89 [01:19<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n",
            "                 all          50          62       0.977       0.979       0.992       0.809\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     35/49       13G   0.02948  0.003998   0.00352     0.037        26       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.18it/s]\n",
            "                 all          50          62       0.956       0.954       0.987       0.819\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     36/49       13G   0.02933  0.004092   0.00298    0.0364        31       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.08it/s]\n",
            "                 all          50          62       0.946       0.969       0.988       0.834\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     37/49       13G   0.02886  0.003939  0.003071   0.03587        34       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.17it/s]\n",
            "                 all          50          62        0.94       0.955        0.99       0.804\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     38/49       13G   0.02861  0.003881  0.002934   0.03543        32       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.16it/s]\n",
            "                 all          50          62        0.98       0.965       0.991       0.847\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     39/49       13G   0.02781  0.003871  0.002882   0.03457        33       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.98it/s]\n",
            "                 all          50          62       0.977       0.979       0.993       0.841\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     40/49       13G   0.02774  0.003786   0.00271   0.03424        52       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.15it/s]\n",
            "                 all          50          62       0.967       0.979       0.991       0.842\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     41/49       13G   0.02742  0.003904  0.002987   0.03431        46       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.10it/s]\n",
            "                 all          50          62       0.966       0.969       0.993       0.828\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     42/49       13G   0.02738  0.003755  0.002663    0.0338        39       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.20it/s]\n",
            "                 all          50          62       0.918       0.969       0.981        0.84\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     43/49       13G   0.02685  0.003888  0.002847   0.03359        26       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.15it/s]\n",
            "                 all          50          62       0.979       0.979       0.994        0.84\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     44/49       13G   0.02666  0.003688  0.002651     0.033        25       640: 100% 89/89 [01:18<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.13it/s]\n",
            "                 all          50          62       0.985       0.979       0.994       0.845\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     45/49       13G   0.02698  0.003749  0.002694   0.03343        41       640: 100% 89/89 [01:18<00:00,  1.13it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.18it/s]\n",
            "                 all          50          62       0.983       0.979       0.994       0.843\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     46/49       13G   0.02707  0.003842  0.002592   0.03351        44       640: 100% 89/89 [01:17<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.89it/s]\n",
            "                 all          50          62       0.961        0.98       0.993       0.834\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     47/49       13G   0.02677   0.00374  0.002938   0.03345        33       640: 100% 89/89 [01:16<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.98it/s]\n",
            "                 all          50          62       0.971       0.979       0.993       0.848\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     48/49       13G   0.02664  0.003929  0.002626    0.0332        44       640: 100% 89/89 [01:17<00:00,  1.15it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:00<00:00,  2.19it/s]\n",
            "                 all          50          62       0.984       0.979       0.994        0.86\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     49/49       13G   0.02607   0.00377  0.002658    0.0325        26       640: 100% 89/89 [01:16<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 2/2 [00:01<00:00,  1.37it/s]\n",
            "                 all          50          62       0.976       0.979       0.993       0.858\n",
            "               green          50          32        0.96       0.938       0.988       0.831\n",
            "                 red          50          24           1           1       0.995       0.796\n",
            "              yellow          50           6       0.966           1       0.995       0.946\n",
            "50 epochs completed in 1.140 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 74.8MB\n"
          ]
        }
      ],
      "source": [
        "# run this cell to begin training\n",
        "%cd /content/yolov7\n",
        "!python train.py --batch 16 --epochs 50 --data {dataset.location}/data.yaml --weights 'yolov7_training.pt' --device 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0MpUaTCJro"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We can evaluate the performance of our custom training using the provided evalution script.\n",
        "\n",
        "Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run test\n",
        "!python test.py --task 'test' --batch 16 --data {dataset.location}/data.yaml --weights runs/train/exp/weights/best.pt --device 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIUd_o6rUrJE",
        "outputId": "277fedda-b218-48f2-e9f6-c803b04c3171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/exp/weights/best.pt'], data='/content/yolov7/traffic-lights-1/data.yaml', batch_size=16, img_size=640, conf_thres=0.001, iou_thres=0.65, task='test', device='0', single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project='runs/test', name='exp', exist_ok=False, no_trace=False, v5_metric=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'traffic-lights-1/test/labels' images and labels... 574 found, 0 missing, 0 empty, 0 corrupted: 100% 574/574 [00:00<00:00, 869.91it/s]\n",
            "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: traffic-lights-1/test/labels.cache\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 36/36 [00:11<00:00,  3.04it/s]\n",
            "                 all         574         764       0.955       0.877       0.933       0.603\n",
            "               green         574         284       0.966       0.908       0.953       0.612\n",
            "                 red         574         407       0.961       0.905       0.952       0.588\n",
            "              yellow         574          73       0.937       0.818       0.892       0.609\n",
            "Speed: 13.2/1.8/14.9 ms inference/NMS/total per 640x640 image at batch-size 16\n",
            "Results saved to runs/test/exp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {dataset.location}/custom/Photos.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZcgCq-hDTQ2",
        "outputId": "c2e2fe60-04a1-4e39-9bb5-28c1e0843264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/yolov7/traffic-lights-1/custom/Photos.zip\n",
            "warning [/content/yolov7/traffic-lights-1/custom/Photos.zip]:  19074896 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n",
            "file #1:  bad zipfile offset (local header sig):  19074896\n",
            "  (attempting to re-compensate)\n",
            "file #1:  bad zipfile offset (local header sig):  19074896\n",
            "error: invalid zip file with overlapped components (possible zip bomb)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.1 --source {dataset.location}/custom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dShEcCjIYl5t",
        "outputId": "194f737e-e838-4a1d-922a-a6409414d944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/exp/weights/best.pt'], source='/content/yolov7/traffic-lights-1/custom', img_size=640, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            " traced_script_module saved! \n",
            " model is traced! \n",
            "\n",
            "1 red, Done. (17.0ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/1.jpg\n",
            "2 greens, 1 red, 1 yellow, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/10.jpg\n",
            "4 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/100.jpeg\n",
            "4 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/101.jpeg\n",
            "1 green, 4 reds, Done. (17.2ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/102.jpeg\n",
            "4 reds, Done. (17.1ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/103.jpeg\n",
            "4 reds, Done. (17.1ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/104.jpeg\n",
            "3 reds, Done. (17.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/105.jpeg\n",
            "1 green, 3 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/106.jpeg\n",
            "3 reds, Done. (17.1ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/107.jpeg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/108.jpeg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/109.jpeg\n",
            "2 greens, 1 red, 1 yellow, Done. (17.2ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/11.jpg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/110.jpeg\n",
            "4 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/111.jpeg\n",
            "1 green, 2 reds, Done. (17.1ms) Inference, (2.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/112.jpeg\n",
            "2 greens, 1 red, Done. (17.2ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/113.jpeg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/114.jpeg\n",
            "1 green, 1 red, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/115.jpeg\n",
            "1 green, 2 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/116.jpeg\n",
            "2 greens, 2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/117.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/118.jpeg\n",
            "4 greens, 2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/119.jpeg\n",
            "3 greens, 1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/12.jpg\n",
            "1 green, 2 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/120.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/121.jpeg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/122.jpeg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/123.jpeg\n",
            "3 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/124.jpeg\n",
            "3 greens, Done. (17.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/125.jpeg\n",
            "3 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/126.jpeg\n",
            "3 greens, Done. (17.1ms) Inference, (2.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/127.jpeg\n",
            "4 greens, Done. (17.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/128.jpeg\n",
            "4 greens, Done. (17.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/129.jpeg\n",
            "1 green, 1 red, 1 yellow, Done. (17.1ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/13.jpg\n",
            "4 greens, Done. (17.1ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/130.jpeg\n",
            "2 reds, 4 yellows, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/131.jpeg\n",
            "1 green, 1 red, 4 yellows, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/132.jpeg\n",
            "2 greens, 2 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/133.jpeg\n",
            "3 reds, Done. (16.9ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/134.jpeg\n",
            "3 reds, Done. (17.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/135.jpeg\n",
            "4 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/136.jpeg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/137.jpeg\n",
            "4 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/138.jpeg\n",
            "4 greens, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/139.jpeg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/14.jpg\n",
            "4 greens, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/140.jpeg\n",
            "3 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/141.jpeg\n",
            "3 greens, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/142.jpeg\n",
            "3 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/143.jpeg\n",
            "2 yellows, Done. (17.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/144.jpeg\n",
            "1 red, 2 yellows, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/145.jpeg\n",
            "1 green, 1 red, 3 yellows, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/146.jpeg\n",
            "2 reds, 2 yellows, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/147.jpeg\n",
            "1 red, Done. (17.1ms) Inference, (1.8ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/148.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/149.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/15.jpg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/150.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/151.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/3.jpg\n",
            "2 reds, Done. (17.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/30.jpg\n",
            "2 reds, Done. (17.2ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/31.jpg\n",
            "2 greens, Done. (17.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/32.jpg\n",
            "1 green, 3 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/33.jpg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/34.jpg\n",
            "Done. (16.3ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/35.jpg\n",
            "1 green, 2 reds, Done. (17.0ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/36.jpg\n",
            "4 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/37.jpg\n",
            "5 greens, 2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/38.jpg\n",
            "1 green, 5 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/39.jpg\n",
            "1 green, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/4.jpg\n",
            "4 greens, 1 yellow, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/40.jpg\n",
            "1 red, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/41.jpg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/42.jpg\n",
            "2 reds, Done. (17.1ms) Inference, (1.9ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/43.jpg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/44.jpg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/45.jpg\n",
            "1 green, Done. (17.1ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/46.jpg\n",
            "1 green, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/47.jpg\n",
            "1 yellow, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/48.jpg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/49.jpg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/5.jpg\n",
            "2 greens, 2 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/50.jpg\n",
            "2 greens, 3 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/51.jpg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/52.jpg\n",
            "1 red, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/53.jpg\n",
            "3 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/54.jpg\n",
            "1 green, 2 reds, 1 yellow, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/55.jpeg\n",
            "2 greens, 2 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/56.jpeg\n",
            "1 green, 1 red, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/57.jpeg\n",
            "1 green, 1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/58.jpeg\n",
            "1 green, 1 red, Done. (17.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/59.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/6.jpg\n",
            "2 greens, Done. (17.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/60.jpeg\n",
            "2 greens, Done. (17.2ms) Inference, (2.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/61.jpeg\n",
            "2 greens, Done. (17.2ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/62.jpeg\n",
            "3 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/63.jpeg\n",
            "1 red, 1 yellow, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/64.jpeg\n",
            "1 red, 2 yellows, Done. (17.1ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/65.jpeg\n",
            "2 reds, 1 yellow, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/66.jpeg\n",
            "1 green, 2 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/67.jpeg\n",
            "2 greens, 2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/68.jpeg\n",
            "1 green, 1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/69.jpeg\n",
            "1 green, 2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/7.jpg\n",
            "2 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/70.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/71.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/72.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/73.jpeg\n",
            "3 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/74.jpeg\n",
            "2 greens, 2 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/75.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/76.jpeg\n",
            "3 greens, Done. (17.2ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/77.jpeg\n",
            "2 greens, 1 red, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/78.jpeg\n",
            "5 greens, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/79.jpeg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/8.jpg\n",
            "4 greens, 1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/80.jpeg\n",
            "2 greens, 1 red, Done. (17.2ms) Inference, (1.7ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/81.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/82.jpeg\n",
            "1 green, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/83.jpeg\n",
            "2 reds, Done. (17.2ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/84.jpeg\n",
            "1 green, 2 reds, Done. (17.2ms) Inference, (1.4ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/85.jpeg\n",
            "2 greens, 1 red, Done. (17.2ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/86.jpeg\n",
            "2 greens, 2 reds, Done. (17.2ms) Inference, (1.6ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/87.jpeg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/88.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.5ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/89.jpeg\n",
            "1 green, 1 yellow, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/9.jpg\n",
            "2 greens, 1 red, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/90.jpeg\n",
            "2 greens, 4 reds, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/91.jpeg\n",
            "2 greens, 1 red, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/92.jpeg\n",
            "1 red, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/93.jpeg\n",
            "2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/94.jpeg\n",
            "Done. (17.1ms) Inference, (0.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/95.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/96.jpeg\n",
            "1 green, 1 red, Done. (17.1ms) Inference, (1.3ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/97.jpeg\n",
            "1 green, 2 reds, Done. (17.1ms) Inference, (1.1ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/98.jpeg\n",
            "2 greens, Done. (17.1ms) Inference, (1.2ms) NMS\n",
            " The image with the result is saved in: runs/detect/exp3/99.jpeg\n",
            "Done. (60.569s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/results.zip /content/yolov7/runs/detect/exp3\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/results.zip\")"
      ],
      "metadata": {
        "id": "3SbVdOqTDpmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0fc34f8e-63ae-48ce-ef11-6c1ff35cc3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/yolov7/runs/detect/exp3/ (stored 0%)\n",
            "  adding: content/yolov7/runs/detect/exp3/46.jpg (deflated 15%)\n",
            "  adding: content/yolov7/runs/detect/exp3/123.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/40.jpg (deflated 15%)\n",
            "  adding: content/yolov7/runs/detect/exp3/58.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/36.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/117.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/86.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/34.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/113.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/11.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/13.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/84.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/60.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/64.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/114.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/128.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/142.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/70.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/31.jpg (deflated 14%)\n",
            "  adding: content/yolov7/runs/detect/exp3/79.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/116.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/3.jpg (deflated 7%)\n",
            "  adding: content/yolov7/runs/detect/exp3/150.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/66.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/72.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/124.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/57.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/1.jpg (deflated 6%)\n",
            "  adding: content/yolov7/runs/detect/exp3/42.jpg (deflated 10%)\n",
            "  adding: content/yolov7/runs/detect/exp3/10.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/32.jpg (deflated 13%)\n",
            "  adding: content/yolov7/runs/detect/exp3/61.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/127.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/109.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/148.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/107.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/145.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/47.jpg (deflated 10%)\n",
            "  adding: content/yolov7/runs/detect/exp3/136.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/8.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/65.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/106.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/83.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/90.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/139.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/137.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/99.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/96.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/111.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/73.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/82.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/147.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/108.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/44.jpg (deflated 9%)\n",
            "  adding: content/yolov7/runs/detect/exp3/103.jpeg (deflated 3%)\n",
            "  adding: content/yolov7/runs/detect/exp3/52.jpg (deflated 10%)\n",
            "  adding: content/yolov7/runs/detect/exp3/78.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/51.jpg (deflated 11%)\n",
            "  adding: content/yolov7/runs/detect/exp3/41.jpg (deflated 9%)\n",
            "  adding: content/yolov7/runs/detect/exp3/77.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/5.jpg (deflated 14%)\n",
            "  adding: content/yolov7/runs/detect/exp3/6.jpg (deflated 18%)\n",
            "  adding: content/yolov7/runs/detect/exp3/75.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/93.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/91.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/85.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/43.jpg (deflated 14%)\n",
            "  adding: content/yolov7/runs/detect/exp3/119.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/59.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/146.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/126.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/135.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/69.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/138.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/102.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/134.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/112.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/49.jpg (deflated 20%)\n",
            "  adding: content/yolov7/runs/detect/exp3/39.jpg (deflated 14%)\n",
            "  adding: content/yolov7/runs/detect/exp3/118.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/71.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/76.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/120.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/115.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/121.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/105.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/100.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/97.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/81.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/133.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/68.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/129.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/141.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/125.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/80.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/144.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/67.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/38.jpg (deflated 13%)\n",
            "  adding: content/yolov7/runs/detect/exp3/143.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/87.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/50.jpg (deflated 14%)\n",
            "  adding: content/yolov7/runs/detect/exp3/33.jpg (deflated 10%)\n",
            "  adding: content/yolov7/runs/detect/exp3/88.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/55.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/131.jpeg (deflated 3%)\n",
            "  adding: content/yolov7/runs/detect/exp3/37.jpg (deflated 14%)\n",
            "  adding: content/yolov7/runs/detect/exp3/14.jpg (deflated 10%)\n",
            "  adding: content/yolov7/runs/detect/exp3/48.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/151.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/63.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/122.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/53.jpg (deflated 11%)\n",
            "  adding: content/yolov7/runs/detect/exp3/12.jpg (deflated 11%)\n",
            "  adding: content/yolov7/runs/detect/exp3/45.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/98.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/30.jpg (deflated 12%)\n",
            "  adding: content/yolov7/runs/detect/exp3/15.jpg (deflated 11%)\n",
            "  adding: content/yolov7/runs/detect/exp3/130.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/56.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/95.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/94.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/140.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/110.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/74.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/62.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/4.jpg (deflated 13%)\n",
            "  adding: content/yolov7/runs/detect/exp3/7.jpg (deflated 11%)\n",
            "  adding: content/yolov7/runs/detect/exp3/9.jpg (deflated 16%)\n",
            "  adding: content/yolov7/runs/detect/exp3/92.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/101.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/35.jpg (deflated 5%)\n",
            "  adding: content/yolov7/runs/detect/exp3/132.jpeg (deflated 2%)\n",
            "  adding: content/yolov7/runs/detect/exp3/149.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/54.jpg (deflated 10%)\n",
            "  adding: content/yolov7/runs/detect/exp3/89.jpeg (deflated 1%)\n",
            "  adding: content/yolov7/runs/detect/exp3/104.jpeg (deflated 3%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ae87f4f-98b6-4ede-8007-f7ab0555b114\", \"results.zip\", 301363843)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4cfnLtTCIce",
        "outputId": "2cb2a7c9-7b3d-4fb6-8dcd-67ee7b737d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(weights=['runs/train/exp/weights/best.pt'], source='/content/yolov7/traffic-lights-1/test/images', img_size=640, conf_thres=0.1, iou_thres=0.45, device='', view_img=False, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='runs/detect', name='exp', exist_ok=False, no_trace=False)\n",
            "YOLOR ðŸš€ v0.1-122-g3b41c2c torch 2.0.0+cu118 CUDA:0 (Tesla T4, 15101.8125MB)\n",
            "\n",
            "Fusing layers... \n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "RepConv.fuse_repvgg_block\n",
            "IDetect.fuse\n",
            "/usr/local/lib/python3.9/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 314 layers, 36492560 parameters, 6194944 gradients, 103.2 GFLOPS\n",
            " Convert model to Traced-model... \n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Run evaluation\n",
        "# !python detect.py --weights runs/train/exp/weights/best.pt --conf 0.1 --source {dataset.location}/test/images\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "my_dir = \"/content/yolov7/traffic-lights-1/custom\"\n",
        "for i in range(154, 293):\n",
        "    fname = str(i) + \".jpg\"\n",
        "    os.remove(os.path.join(my_dir, fname))"
      ],
      "metadata": {
        "id": "27an-70LgWBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AGhNOSSHY4_"
      },
      "outputs": [],
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000 # max images to print\n",
        "for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMOfi7eLJCT3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMumI7a2JDAN"
      },
      "source": [
        "# Reparameterize for Inference\n",
        "\n",
        "https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jn4kCtgKiGO"
      },
      "source": [
        "# OPTIONAL: Deployment\n",
        "\n",
        "To deploy, you'll need to export your weights and save them to use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWOok8abrCsL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40da4b78-5839-46d8-fd16-c5ac7b3db198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: runs/detect\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r export.zip . -i runs/detect)\n",
            "  adding: runs/train/exp/weights/best.pt (deflated 8%)\n",
            "  adding: runs/train/exp/confusion_matrix.png (deflated 35%)\n",
            "  adding: runs/train/exp/events.out.tfevents.1680551820.2d52b2eec91d.2013.0 (deflated 63%)\n",
            "  adding: runs/train/exp/F1_curve.png (deflated 11%)\n",
            "  adding: runs/train/exp/hyp.yaml (deflated 44%)\n",
            "  adding: runs/train/exp/opt.yaml (deflated 46%)\n",
            "  adding: runs/train/exp/P_curve.png (deflated 14%)\n",
            "  adding: runs/train/exp/PR_curve.png (deflated 28%)\n",
            "  adding: runs/train/exp/R_curve.png (deflated 14%)\n",
            "  adding: runs/train/exp/results.png (deflated 10%)\n",
            "  adding: runs/train/exp/results.txt (deflated 71%)\n",
            "  adding: runs/train/exp/test_batch0_labels.jpg (deflated 3%)\n",
            "  adding: runs/train/exp/test_batch0_pred.jpg (deflated 3%)\n",
            "  adding: runs/train/exp/test_batch1_labels.jpg (deflated 2%)\n",
            "  adding: runs/train/exp/test_batch1_pred.jpg (deflated 2%)\n",
            "  adding: runs/train/exp/train_batch0.jpg (deflated 2%)\n",
            "  adding: runs/train/exp/train_batch1.jpg (deflated 2%)\n",
            "  adding: runs/train/exp/train_batch2.jpg (deflated 1%)\n",
            "  adding: runs/train/exp/train_batch3.jpg (deflated 4%)\n",
            "  adding: runs/train/exp/train_batch4.jpg (deflated 5%)\n",
            "  adding: runs/train/exp/train_batch5.jpg (deflated 4%)\n",
            "  adding: runs/train/exp/train_batch6.jpg (deflated 3%)\n",
            "  adding: runs/train/exp/train_batch7.jpg (deflated 7%)\n",
            "  adding: runs/train/exp/train_batch8.jpg (deflated 3%)\n",
            "  adding: runs/train/exp/train_batch9.jpg (deflated 5%)\n",
            "  adding: runs/train/exp/weights/ (stored 0%)\n"
          ]
        }
      ],
      "source": [
        "# optional, zip to download weights and results locally\n",
        "\n",
        "!zip -r export.zip runs/detect\n",
        "!zip -r export.zip runs/train/exp/weights/best.pt\n",
        "!zip export.zip runs/train/exp/*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}